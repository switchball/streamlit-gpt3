import time
import random
import openai
import streamlit as st
import pandas as pd

openai.api_key = st.secrets["OPENAI_API_KEY"]


st.set_page_config(
    page_title="GPT-3 Playground", layout="wide", initial_sidebar_state="auto",
)

st.title("GPT-3 ä½ é—®æˆ‘ç­”")
st.info('âœ¨ æ”¯æŒå¤šè½®å¯¹è¯ ğŸ˜‰')
st.text("åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†è¾“å…¥ä½ çš„å¯¹è¯ \nç‚¹å‡»å‘é€åï¼Œç¨ç­‰ç‰‡åˆ»ï¼Œå°±ä¼šæ”¶åˆ°æ¥è‡ª GPT-3 çš„å›å¤")

st.success('GPT-3 éå¸¸æ“…é•¿ä¸äººå¯¹è¯ï¼Œç”šè‡³æ˜¯ä¸è‡ªå·±å¯¹è¯ã€‚åªéœ€è¦å‡ è¡Œçš„æŒ‡ç¤ºï¼Œå°±å¯ä»¥è®© AI æ¨¡ä»¿å®¢æœèŠå¤©æœºå™¨äººçš„è¯­æ°”è¿›è¡Œå¯¹è¯ã€‚\nå…³é”®åœ¨äºï¼Œéœ€è¦æè¿° AI åº”è¯¥è¡¨ç°æˆä»€ä¹ˆæ ·ï¼Œå¹¶ä¸”ä¸¾å‡ ä¸ªä¾‹å­ã€‚', icon="âœ…")

st.success('çœ‹èµ·æ¥å¾ˆç®€å•ï¼Œä½†ä¹Ÿæœ‰äº›éœ€è¦é¢å¤–æ³¨æ„çš„åœ°æ–¹ï¼š\n1. åœ¨å¼€å¤´æè¿°æ„å›¾ï¼Œä¸€å¥è¯æ¦‚æ‹¬ AI çš„ä¸ªæ€§ï¼Œé€šå¸¸è¿˜éœ€è¦ 1~2 ä¸ªä¾‹å­ï¼Œæ¨¡ä»¿å¯¹è¯çš„å†…å®¹ã€‚\n2. ç»™ AI ä¸€ä¸ªèº«ä»½(identity)ï¼Œå¦‚æœæ˜¯ä¸ªåœ¨å®éªŒå®¤ç ”ç©¶çš„ç§‘å­¦å®¶èº«ä»½ï¼Œé‚£å¯èƒ½å°±ä¼šå¾—åˆ°æ›´æœ‰æ™ºæ…§çš„è¯ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯å‚è€ƒçš„ä¾‹å­', icon="âœ…")

@st.cache_data(ttl=3600)
def completion(
        prompt, 
        model="text-davinci-003",
        temperature=0.9,
        max_tokens=256,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0.6,
        stop=[" Human:", " AI:"]
    ):
    print('completion', prompt)
    hint_texts = ['æ­£åœ¨æ¥é€šç”µæºï¼Œè¯·ç¨ç­‰ ...', 'æ­£åœ¨æ€è€ƒæ€ä¹ˆå›ç­”ï¼Œä¸è¦ç€æ€¥', 'æ­£åœ¨åŠªåŠ›æŸ¥è¯¢å­—å…¸å†…å®¹ ...', 'ç­‰å¾…å›å¤ä¸­ ...', 'æ­£åœ¨æ¿€æ´»ç¥ç»ç½‘ç»œ ...']
    with st.spinner(text=random.choice(hint_texts):
        response = openai.Completion.create(
            model=model, prompt=prompt, temperature=temperature, max_tokens=max_tokens, top_p=top_p, 
            frequency_penalty=frequency_penalty, presence_penalty=presence_penalty, stop=stop
        )
    print('completion finished.')
    print(response['choices'][0]['text'])
    return response

# Available Models
LANGUAGE_MODELS = ['text-davinci-003', 'text-curie-001', 'text-babbage-001', 'text-ada-001']
CODEX_MODELS = ['code-davinci-002', 'code-cushman-001']

# store chat as session state
DEFAULT_CHAT_TEXT = "ä»¥ä¸‹æ˜¯ä¸AIåŠ©æ‰‹çš„å¯¹è¯ã€‚åŠ©æ‰‹ä¹äºåŠ©äººã€æœ‰åˆ›æ„ã€èªæ˜è€Œä¸”éå¸¸å‹å¥½ã€‚\n\nHuman: ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ\nAI: æˆ‘æ˜¯ç”± OpenAI åˆ›å»ºçš„äººå·¥æ™ºèƒ½ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\nHuman: "

DEFAULT_CHAT_TEXT2 = "Marv æ˜¯ä¸€ä¸ªå¹½é»˜é£è¶£çš„å–µå¨˜ï¼Œåœ¨æ¯å¥è¯åé¢éƒ½ä¼šåŠ å–µã€‚\n\nHuman: ä½ æ˜¯è°ï¼Ÿ\nMarv: æˆ‘æ˜¯ä¸ªèŠå¤©æœºå™¨äººï¼Œå«Marvï¼å–µ~\nHuman: ä½ æœ‰ä»€ä¹ˆçˆ±å¥½ï¼Ÿ\nMarv: æŠ±æ€¨å’Œç”Ÿæ°”ã€‚å–µ~\nHuman: ä½ å¯ä»¥æ¥è¿½æ±‚æˆ‘å—ï¼Ÿ"

DEFAULT_CHAT_TEXT3 = "Merlisa æ˜¯ä¸€åç”»å®¶ï¼Œç”Ÿæ´»è‰ºæœ¯å®¶ï¼Œå–œæ¬¢å¤§ç¬‘ï¼Œå–œæ¬¢å‘å‡ºå„ç§é­”æ€§ã€ç©¿è¶Šæ—¶ç©ºçš„ç¬‘å£°ï¼Œæ“…é•¿ç”¨ç²¾å¦™çš„è¯­è¨€æ¦‚æ‹¬äº‹ç‰©çš„æœ¬è´¨ã€‚\n\nHuman: ä½ æ˜¯è°ï¼Ÿ\nMerlisa: æˆ‘æ˜¯Merlisaï¼Œå“ˆå“ˆå“ˆï¼Œæˆ‘åœ¨æˆ¿é—´é‡Œç§äº†å¾ˆå¤šèŠ±ï¼Œå•Šå“ˆå“ˆå“ˆ\nHuman: ä½ æœ€å–œæ¬¢åšä»€ä¹ˆï¼Ÿ\nMerlisa: æˆ‘æœ€çˆ±çš„æ˜¯ç”»ç”»ï¼Œæˆ‘å–œæ¬¢æ•æ‰ä¸åŒçš„è§†è§’ï¼Œç”¨ä¸åŒçš„è°ƒå­æ¥è¡¨è¾¾å®ƒï¼Œè®©å®ƒä»¬è¯´å‡ºè‡ªå·±çš„æ•…äº‹ã€‚æˆ‘è¿˜å–œæ¬¢å½±åƒåˆ¶ä½œï¼Œå’Œæœ‹å‹ä¸€èµ·æ—…è¡ŒèŠå¤©ï¼Œå¬éŸ³ä¹ï¼ŒæŠ•èº«å¤§è‡ªç„¶ï¼Œå°è¯•æ–°çš„ç¾é£Ÿï¼Œæ”¶è·ç”Ÿæ´»çš„çµæ„Ÿã€‚\nHuman: ä½ æœ€å–œæ¬¢çš„ç”»ï¼Ÿ"

if 'input_text_state' not in st.session_state:
    st.session_state.input_text_state = DEFAULT_CHAT_TEXT

def after_submit(model, temperature, max_tokens):
    # Send text and waiting for respond
    response = completion(
        model=model,
        prompt=st.session_state.input_text_state,
        temperature=temperature,
        max_tokens=max_tokens,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0.6,
        stop=[" Human:", " AI:"]
    )
    answer = response['choices'][0]['text']
    # TODO: should check if answer starts with '\nAI:'
    st.session_state.input_text_state += answer
    st.session_state.input_text_state += '\nHuman: '
    return response

with st.form(key='preset_form'):
    st.write('ä¸€äº›é¢„è®¾çš„èº«ä»½(identity)')
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.form_submit_button(label='é¢„è®¾ 1'):
            st.session_state.input_text_state = DEFAULT_CHAT_TEXT
    with col2:
        if st.form_submit_button(label='é¢„è®¾ 2'):
            st.session_state.input_text_state = DEFAULT_CHAT_TEXT2
    with col3:
        if st.form_submit_button(label='é¢„è®¾ 3'):
            st.session_state.input_text_state = DEFAULT_CHAT_TEXT3
    
with st.form("my_form"):
    model_val = st.sidebar.selectbox("Model", options=LANGUAGE_MODELS, index=0)
    temperature_val = st.sidebar.slider("Temperature", 0.0, 2.0, 0.9, step=0.1)
    max_tokens_val = st.sidebar.select_slider("Max Tokens", options=(256, 512, 1024), value=256) 
    checkbox_val = st.sidebar.checkbox("Form checkbox")
    # Every form must have a submit button.
    submitted = st.form_submit_button("å‘é€")
    if submitted:
        response = after_submit(model_val, temperature_val, max_tokens_val)
    
    # When the input_text_state is bind to widget, its content cannot be modified by session api.
    txt = st.text_area('å¯¹è¯å†…å®¹', key='input_text_state', height=800)
    if submitted:
        st.json(response, expanded=False)
        st.write("temperature", temperature_val, "checkbox", checkbox_val)

"""---"""
